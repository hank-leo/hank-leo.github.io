<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Scrapy框架:爬取链家二手房信息 | Hank&#39;s Blog</title>
    <meta property="og:title" content="Scrapy框架:爬取链家二手房信息 - Hank&#39;s Blog">
    <meta property="og:type" content="article">
        
    <meta property="article:published_time" content='2019-12-04T00:00:00&#43;08:00'>
        
        
    <meta property="article:modified_time" content='2019-12-04T00:00:00&#43;08:00'>
        
    <meta name="Keywords" content="Hank,博客,python">
    <meta name="description" content="Scrapy框架:爬取链家二手房信息">
        
    <meta name="author" content="Hank">
    <meta property="og:url" content="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%88%AC%E5%8F%96%E9%93%BE%E5%AE%B6%E4%BA%8C%E6%89%8B%E6%88%BF%E4%BF%A1%E6%81%AF/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
        <link rel="stylesheet" href='/css/douban.css'>
    
        <link rel="stylesheet" href='/css/other.css'>
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://hank-leo.github.io">
                        Hank&#39;s Blog
                    </a>
                
                <p class="description">专注于Python、JavaScript、SQL、爬虫、数据分析与挖掘</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://hank-leo.github.io">首页</a>
                    
                    <a  href="https://hank-leo.github.io/archives/" title="归档">归档</a>
                    
                    <a  href="https://hank-leo.github.io/tags/" title="标签">标签</a>
                    
                    <a  href="https://hank-leo.github.io/categories/" title="分类">分类</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    <style type="text/css">
    .post-toc {
        position: fixed;
        width: 200px;
        margin-left: -210px;
        padding: 5px 10px;
        font-family: Athelas, STHeiti, Microsoft Yahei, serif;
        font-size: 12px;
        border: 1px solid rgba(0, 0, 0, .07);
        border-radius: 5px;
        background-color: rgba(255, 255, 255, 0.98);
        background-clip: padding-box;
        -webkit-box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        box-shadow: 1px 1px 2px rgba(0, 0, 0, .125);
        word-wrap: break-word;
        white-space: nowrap;
        -webkit-box-sizing: border-box;
        box-sizing: border-box;
        z-index: 999;
        cursor: pointer;
        max-height: 70%;
        overflow-y: auto;
        overflow-x: hidden;
    }

    .post-toc .post-toc-title {
        width: 100%;
        margin: 0 auto;
        font-size: 20px;
        font-weight: 400;
        text-transform: uppercase;
        text-align: center;
    }

    .post-toc .post-toc-content {
        font-size: 15px;
    }

    .post-toc .post-toc-content>nav>ul {
        margin: 10px 0;
    }

    .post-toc .post-toc-content ul {
        padding-left: 20px;
        list-style: square;
        margin: 0.5em;
        line-height: 1.8em;
    }

    .post-toc .post-toc-content ul ul {
        padding-left: 15px;
        display: none;
    }

    @media print,
    screen and (max-width:1057px) {
        .post-toc {
            display: none;
        }
    }
</style>
<div class="post-toc" style="position: absolute; top: 188px;">
    <h2 class="post-toc-title">文章目录</h2>
    <div class="post-toc-content">
        <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav>
    </div>
</div>
<script type="text/javascript">
    $(document).ready(function () {
        var postToc = $(".post-toc");
        if (postToc.length) {
            var leftPos = $("#main").offset().left;
            if(leftPos<220){
                postToc.css({"width":leftPos-10,"margin-left":(0-leftPos)})
            }

            var t = postToc.offset().top - 20,
                a = {
                    start: {
                        position: "absolute",
                        top: t
                    },
                    process: {
                        position: "fixed",
                        top: 20
                    },
                };
            $(window).scroll(function () {
                var e = $(window).scrollTop();
                e < t ? postToc.css(a.start) : postToc.css(a.process)
            })
        }
    })
</script>
    <article class="post">
        <header>
            <h1 class="post-title">Scrapy框架:爬取链家二手房信息</h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        
        <div class="post-meta">
            <span id="busuanzi_container_page_pv">|<span id="busuanzi_value_page_pv"></span><span>
                    阅读</span></span>
        </div>
        
        
        <div class="post-content">
            <h4 id="创建爬虫项目">创建爬虫项目</h4>
<pre><code>scrapy startproject lianjiahouse
</code></pre><h4 id="创建爬虫文件">创建爬虫文件</h4>
<pre><code>scrapy genspider -t craw house lianjia.com
</code></pre><h4 id="编写itemspy文件">编写items.py文件</h4>
<pre><code># -*- coding: utf-8 -*-

# Define here the models for your scraped items
#
# See documentation in:
# https://doc.scrapy.org/en/latest/topics/items.html

import scrapy

class LianjiahouseItem(scrapy.Item):
    # define the fields for your item here like:
    # name = scrapy.Field()
    # 发布信息名称
    house_name = scrapy.Field()
    # 小区名称
    community_name = scrapy.Field()
    # 所在区域
    # location = scrapy.Field()
    # 链家编号
    house_record = scrapy.Field()
    # 总售价
    total_amount = scrapy.Field()
    # 单价
    unit_price = scrapy.Field()
    # 房屋基本信息
    # 建筑面积
    area_total = scrapy.Field()
    # 套内面积
    area_use = scrapy.Field()
    # 厅室户型
    house_type = scrapy.Field()
    # 朝向
    direction = scrapy.Field()
    # 装修情况
    sub_info = scrapy.Field()
    # 供暖方式
    heating_method = scrapy.Field()
    # 产权
    house_property = scrapy.Field()
    # 楼层
    floor = scrapy.Field()
    # 总层高
    total_floors = scrapy.Field()
    # 电梯
    is_left = scrapy.Field()
    # 户梯比例
    left_rate = scrapy.Field()
    # 户型结构
    structure = scrapy.Field()
    # 房屋交易信息
    # 挂牌时间
    release_date = scrapy.Field()
    # 上次交易时间
    last_trade_time = scrapy.Field()
    # 房屋使用年限
    house_years = scrapy.Field()
    # 房屋抵押信息
    pawn = scrapy.Field()
    # 交易权属
    trade_property = scrapy.Field()
    # 房屋用途
    house_usage = scrapy.Field()
    # 产权所有
    property_own = scrapy.Field()
    # 图片地址
    images_urls = scrapy.Field()
    # 保存图片
    images = scrapy.Field()
</code></pre><h4 id="编写pipelinespy">编写pipelines.py</h4>
<pre><code># -*- coding: utf-8 -*-

# Define your item pipelines here
# Don't forget to add your pipeline to the ITEM_PIPELINES setting
# See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html

import pymongo
from scrapy.pipelines.images import ImagesPipeline
from scrapy import Request

class LianjiahousePipeline(object):
    # 设置存储文档名称
    collection_name = 'lianjiahouse'

    def __init__(self, mongo_uri, mongo_db):
        self.mongo_uri = mongo_uri
        self.mongo_db = mongo_db

    @classmethod
    def from_crawler(cls, crawler):
        return cls(
            # 通过crawler获取settings文件，获取其中的MongoDB配置信息
            mongo_uri=crawler.settings.get('MONGO_URI'),
            mongo_db=crawler.settings.get('MONGO_DATABASE', 'lianjia')
        )

    def open_spider(self, spider):
        # 当爬虫打开时连接MongoDB数据库
        # 先连接server，在连接指定数据库
        self.client = pymongo.MongoClient(self.mongo_uri)
        self.db = self.client[self.mongo_db]

    def close_spider(self, spider):
        # 爬虫结束时关闭数据库连接
        self.client.close()

    def process_item(self, item, spider):
        # 将item插入数据库
        self.db[self.collection_name].insert(dict(item))
        return item

class LianjiaImagePipeline(ImagesPipeline):
    def get_media_requests(self, item, info):
        for image_url in item['images_urls']:
            # 将图片地址传入Request，进行下载，同时将item做参数添加到Request中
            yield Request(image_url, meta={'item': item})

    def file_path(self, request, response=None, info=None):
        # 从Request中获取item，以房屋标题做文件夹名称
        item = request.meta['item']
        image_folder = item['house_name']
        # 使用图片url做图片存储名称
        image_guild = request.url.split('/')[-1]
        # 图片保存，文件夹/图片
        image_save = u'{0}/{1}'.format(image_folder, image_guild)
        return image_save
</code></pre><h4 id="编写settingspy">编写settings.py</h4>
<pre><code># -*- coding: utf-8 -*-

# Scrapy settings for lianjiahouse project
#
# For simplicity, this file contains only settings considered important or
# commonly used. You can find more settings consulting the documentation:
#
#     https://doc.scrapy.org/en/latest/topics/settings.html
#     https://doc.scrapy.org/en/latest/topics/downloader-middleware.html
#     https://doc.scrapy.org/en/latest/topics/spider-middleware.html

BOT_NAME = 'lianjiahouse'

SPIDER_MODULES = ['lianjiahouse.spiders']
NEWSPIDER_MODULE = 'lianjiahouse.spiders'


# Crawl responsibly by identifying yourself (and your website) on the user-agent
#USER_AGENT = 'lianjiahouse (+http://www.yourdomain.com)'

# Obey robots.txt rules
ROBOTSTXT_OBEY = True

# Configure maximum concurrent requests performed by Scrapy (default: 16)
#CONCURRENT_REQUESTS = 32

# Configure a delay for requests for the same website (default: 0)
# See https://doc.scrapy.org/en/latest/topics/settings.html#download-delay
# See also autothrottle settings and docs
#DOWNLOAD_DELAY = 3
# The download delay setting will honor only one of:
#CONCURRENT_REQUESTS_PER_DOMAIN = 16
#CONCURRENT_REQUESTS_PER_IP = 16

# Disable cookies (enabled by default)
#COOKIES_ENABLED = False

# Disable Telnet Console (enabled by default)
#TELNETCONSOLE_ENABLED = False

# Override the default request headers:
#DEFAULT_REQUEST_HEADERS = {
#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
#   'Accept-Language': 'en',
#}

# Enable or disable spider middlewares
# See https://doc.scrapy.org/en/latest/topics/spider-middleware.html
SPIDER_MIDDLEWARES = {
   'lianjiahouse.middlewares.LianjiahouseSpiderMiddleware': 543,
}

# Enable or disable downloader middlewares
# See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html
DOWNLOADER_MIDDLEWARES = {
   'lianjiahouse.middlewares.LianjiahouseDownloaderMiddleware': 543,
}

# Enable or disable extensions
# See https://doc.scrapy.org/en/latest/topics/extensions.html
#EXTENSIONS = {
#    'scrapy.extensions.telnet.TelnetConsole': None,
#}

# Configure item pipelines
# See https://doc.scrapy.org/en/latest/topics/item-pipeline.html
ITEM_PIPELINES = {
    'lianjiahouse.pipelines.LianjiahousePipeline': 300,
    'lianjiahouse.pipelines.LianjiaImagePipeline':400
}

# Enable and configure the AutoThrottle extension (disabled by default)
# See https://doc.scrapy.org/en/latest/topics/autothrottle.html
#AUTOTHROTTLE_ENABLED = True
# The initial download delay
#AUTOTHROTTLE_START_DELAY = 5
# The maximum download delay to be set in case of high latencies
#AUTOTHROTTLE_MAX_DELAY = 60
# The average number of requests Scrapy should be sending in parallel to
# each remote server
#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0
# Enable showing throttling stats for every response received:
#AUTOTHROTTLE_DEBUG = False

# Enable and configure HTTP caching (disabled by default)
# See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings
#HTTPCACHE_ENABLED = True
#HTTPCACHE_EXPIRATION_SECS = 0
#HTTPCACHE_DIR = 'httpcache'
#HTTPCACHE_IGNORE_HTTP_CODES = []
#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'

# 图片存储配置
IMAGES_STORE = 'D:\\Scrapy\\lianjia\\images'
IMAGES_URLS_FIELD = 'images_urls'
IMAGES_RESULT_FIELD = 'images'

# MongoDB配置信息
MONGO_URI = 'localhost:27017'
MONGO_DATABASE = 'lianjia'

# 代理列表
PROXY_LIST = [
'http://116.209.57.41:9999',
'http://117.90.252.151:9999',
'http://221.239.86.26:32228',
'http://117.95.12.239:9999',
'http://18.223.141.123:80',
'http://121.232.148.113:9000',
'http://120.198.230.65:8080',
'http://113.122.168.105:9999',
'http://218.95.48.156:9000',
'http://115.223.207.109:9000',
'http://183.3.221.186:8118',
'http://114.234.81.72:9000',
'http://111.177.177.87:9999',
'http://60.217.64.237:45091',
'http://36.248.129.240:9999'
]
</code></pre><h4 id="编写middlewarespy">编写middlewares.py</h4>
<pre><code># -*- coding: utf-8 -*-

# Define here the models for your spider middleware
#
# See documentation in:
# https://doc.scrapy.org/en/latest/topics/spider-middleware.html

from scrapy import signals
import scrapy
import random

class LianjiaSpiderMiddleware(object):
    &quot;&quot;&quot;
    利用Scrapy数据收集功能，记录相同小区的数量
    &quot;&quot;&quot;
    def __init__(self, stats):
        self.stats = stats

    @classmethod
    def from_crawler(cls, crawler):
        return cls(stats=crawler.stats)

    def process_spider_output(self, response, result, spider):
        &quot;&quot;&quot;
        从item中获取小区名称，在数据收集其中记录相同小区数量
        :param response:
        :param result:
        :param spider:
        :return:
        &quot;&quot;&quot;
        for item in result:
            if isinstance(item,scrapy.Item):
                # 从result中的item获取小区名称
                community_name = item['community_name']
                # 在数据统计中为相同的小区增加数量值
                self.stats.inc_value(community_name)
            yield item

class LianjiaDownloaderMiddleware(object):
    &quot;&quot;&quot;
    为请求添加代理
    &quot;&quot;&quot;
    def __init__(self,proxy_list):
        self.proxy_list = proxy_list

    @classmethod
    def from_crawler(cls, crawler):
        # 从settings.py中获取代理列表
        return cls(
            proxy_list=crawler.settings.get('PROXY_LIST')
        )

    def process_request(self, request, spider):
        # 从代理列表中随机选取一个添加至请求
        proxy = random.choice(self.proxy_list)
        request.meta['proxy'] = proxy

    def spider_opened(self, spider):
        spider.logger.info('Spider opened: %s' % spider.name)
</code></pre><h4 id="编写爬虫文件housepy">编写爬虫文件house.py</h4>
<pre><code># -*- coding: utf-8 -*-
import scrapy
from scrapy.linkextractors import LinkExtractor
from scrapy.spiders import CrawlSpider, Rule
from lianjiahouse.items import LianjiahouseItem

class HouseSpider(CrawlSpider):
    name = 'lianjiahouse'
    allowed_domains = ['lianjia.com']
    start_urls = ['https://bj.lianjia.com/ershoufang/pg2/']

    rules = (
        Rule(LinkExtractor(allow='/ershoufang/\d{12}.html'), callback='parse_item'),
    )

    def parse_item(self, response):
        i = LianjiahouseItem()
        # 二手房名称
        i['house_name'] = response.css('title::text').extract_first().replace(' ','')
        # 所在小区
        i['community_name'] = response.css('.communityName a::text').extract_first()
        # i['location'] = response.css()
        # 链家编号
        i['house_record'] = response.css('.houseRecord .info::text').extract_first()
        # 总价
        i['total_amount'] = response.css('.overview .total::text').extract_first()
        # 房屋信息
        # 单价
        i['unit_price'] = response.css('.unitPriceValue::text').extract_first()
        # 建筑总面积
        i['area_total'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[3]/text()').re_first('\d+.\d+')
        # 使用面积
        i['area_use'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[5]/text()').re_first('\d+.\d+')
        # 房屋类型
        i['house_type'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[1]/text()').extract_first()
        # 房屋朝向
        i['direction'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[7]/text()').extract_first()
        # 装修情况
        i['sub_info'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[9]/text()').extract_first()
        # 供暖方式
        i['heating_method'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[11]/text()').extract_first()
        # 产权
        i['house_property'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[13]/text()').extract_first()
        # 楼层
        i['floor'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[2]/text()').extract_first()
        # 总楼层
        i['total_floors'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[2]/text()').re_first(r'\d+')
        # 是否有电梯
        i['is_left'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[12]/text()').extract_first()
        # 户梯比例
        i['left_rate'] = response.xpath('//div[@class=&quot;base&quot;]//ul/li[10]/text()').extract_first()
        # 挂牌时间
        i['release_date'] = response.xpath('//div[@class=&quot;transaction&quot;]//ul/li[1]/span[2]/text()').extract_first()
        # 最后交易时间
        i['last_trade_time'] = response.xpath('//div[@class=&quot;transaction&quot;]//ul/li[3]/span[2]/text()').extract_first()
        # 房屋使用年限
        i['house_years'] = response.xpath('//div[@class=&quot;transaction&quot;]//ul/li[5]/span[2]/text()').extract_first()
        # 房屋抵押信息,抵押信息中有空格及换行符，先通过replace()将空格去掉，再通过strip()将换行符去掉
        i['pawn'] = response.xpath('//div[@class=&quot;transaction&quot;]//ul/li[7]/span[2]/text()').extract_first().replace(' ','').strip()
        # 交易权属
        i['trade_property'] = response.xpath('//div[@class=&quot;transaction&quot;]//ul/li[2]/span[2]/text()').extract_first()
        # 房屋用途
        i['house_usage'] = response.xpath('//div[@class=&quot;transaction&quot;]//ul/li[4]/span[2]/text()').extract_first()
        # 产权所有
        i['property_own'] = response.xpath('//div[@class=&quot;transaction&quot;]//ul/li[6]/span[2]/text()').extract_first()
        # 图片url
        i['images_urls'] = response.css('.smallpic &gt; li::attr(data-pic)').extract()
        yield i
</code></pre><p><strong>最后运行爬虫</strong></p>
<pre><code>scrapy crawl house
</code></pre>
        </div>

        
<div class="post-archive">
    <ul class="post-copyright">
        <li><strong>原文作者：</strong><a rel="author" href="https://hank-leo.github.io">Hank</a></li>
        <li style="word-break:break-all"><strong>原文链接：</strong><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%88%AC%E5%8F%96%E9%93%BE%E5%AE%B6%E4%BA%8C%E6%89%8B%E6%88%BF%E4%BF%A1%E6%81%AF/">https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%88%AC%E5%8F%96%E9%93%BE%E5%AE%B6%E4%BA%8C%E6%89%8B%E6%88%BF%E4%BF%A1%E6%81%AF/</a></li>
        <li><strong>版权声明：</strong>本作品采用<a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</a>进行许可，非商业转载请注明出处（作者，原文链接），商业转载请联系作者获得授权。</li>
    </ul>
</div>
<br/>



        

<div class="post-archive">
    <h2>See Also</h2>
    <ul class="listing">
        
        <li><a href="/post/sql/MySQL%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/">MySQL的实际应用</a></li>
        
        <li><a href="/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/">Scrapy框架 基本命令</a></li>
        
        <li><a href="/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%99%BB%E5%BD%95%E7%BD%91%E7%AB%99/">Scrapy框架 登录网站</a></li>
        
        <li><a href="/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-Request%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/">Scrapy框架:Request回调函数</a></li>
        
        <li><a href="/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-settings-py/">Scrapy框架:Settings.py</a></li>
        
    </ul>
</div>


        <div class="post-meta meta-tags">
            
            没有标签
            
        </div>
    </article>
    
    <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "yourdiscussshortname" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

    
    
    <div class="post bg-white">
      <script src="https://utteranc.es/client.js"
            repo= "https://github.com/hank-leo/hank-leo.github.io"
            issue-term="pathname"
            theme="github-light"
            crossorigin="anonymous"
            async>
      </script>
    </div>
    
</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://hank-leo.github.io">Hank&#39;s Blog By Hank</a>
        
    </div>
    <br />
    <div>
        <div class="github-badge">
            <a href="https://gohugo.io/" target="_black" rel="nofollow"><span class="badge-subject">Powered by</span><span class="badge-value bg-blue">Hugo</span></a>
        </div>
        <div class="github-badge">
            <a href="https://www.flysnow.org/" target="_black"><span class="badge-subject">Design by</span><span class="badge-value bg-brightgreen">飞雪无情</span></a>
        </div>
        <div class="github-badge">
            <a href="https://github.com/flysnow-org/maupassant-hugo" target="_black"><span class="badge-subject">Theme</span><span class="badge-value bg-yellowgreen">Maupassant</span></a>
        </div>
    </div>
</footer>


    
    <script type="text/javascript">
        window.MathJax = {
            tex2jax: {
                inlineMath: [['$', '$']],
                processEscapes: true
                }
            };
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>

<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




    <script src='/js/douban.js'></script>

                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://hank-leo.github.io/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://hank-leo.github.io">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://hank-leo.github.io/post/sql/SQL%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/" title="SQL刷题记录">SQL刷题记录</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/blog/%E4%BD%BF%E7%94%A8Github-Actions%E6%90%AD%E5%BB%BAhugo/" title="使用Github Actions搭建hugo">使用Github Actions搭建hugo</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/python/python%E7%BB%83%E4%B9%A0/" title="Python练习">Python练习</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/python/Python%E9%9D%A2%E8%AF%95%E9%A2%98/" title="Python面试题">Python面试题</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/spider/%E7%88%AC%E8%99%AB%E9%9D%A2%E8%AF%95%E9%A2%98/" title="爬虫面试题">爬虫面试题</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/blog/%E4%BD%BF%E7%94%A8hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/" title="使用hexo搭建个人博客">使用hexo搭建个人博客</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-Scrapy&#43;MongoDB%E5%AE%9E%E6%88%98%E6%8A%93%E5%8F%96%E5%B9%B6%E4%BF%9D%E5%AD%98IT%E4%B9%8B%E5%AE%B6%E5%8D%9A%E5%AE%A2%E6%96%B0%E9%97%BB/" title="Scrapy框架:Scrapy&#43;MongoDB实战:抓取并保存IT之家博客新闻">Scrapy框架:Scrapy&#43;MongoDB实战:抓取并保存IT之家博客新闻</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6%E9%80%9A%E7%94%A8%E7%88%AC%E8%99%AB/" title="Scrapy框架:通用爬虫">Scrapy框架:通用爬虫</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/app/%E4%BD%BF%E7%94%A8Airtest%E8%BF%9B%E8%A1%8CApp%E7%88%AC%E8%99%AB/" title="使用Airtest进行App爬虫">使用Airtest进行App爬虫</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/spider/%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B9%8Bexcel/" title="存储数据之excel">存储数据之excel</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
    <li><a href="https://hank-leo.github.io/categories/App%E7%88%AC%E8%99%AB/">App爬虫 (1)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/Pandas%E5%AD%A6%E4%B9%A0/">Pandas学习 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/Python%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/">Python实际应用 (6)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/">Scrapy框架学习 (11)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/">博客搭建 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/">数据库学习 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/">爬虫学习 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/">面试题 (2)</a></li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://hank-leo.github.io/tags/MongoDB/">MongoDB</a>
    
    <a href="https://hank-leo.github.io/tags/MySQL/">MySQL</a>
    
    <a href="https://hank-leo.github.io/tags/Scrapy/">Scrapy</a>
    
    <a href="https://hank-leo.github.io/tags/airtest/">airtest</a>
    
    <a href="https://hank-leo.github.io/tags/dict/">dict</a>
    
    <a href="https://hank-leo.github.io/tags/excel/">excel</a>
    
    <a href="https://hank-leo.github.io/tags/hexo/">hexo</a>
    
    <a href="https://hank-leo.github.io/tags/hugo/">hugo</a>
    
    <a href="https://hank-leo.github.io/tags/list/">list</a>
    
    <a href="https://hank-leo.github.io/tags/pandas/">pandas</a>
    
    <a href="https://hank-leo.github.io/tags/re/">re</a>
    
    <a href="https://hank-leo.github.io/tags/regex/">regex</a>
    
    <a href="https://hank-leo.github.io/tags/string/">string</a>
    
    <a href="https://hank-leo.github.io/tags/xpath/">xpath</a>
    
    <a href="https://hank-leo.github.io/tags/%E7%88%AC%E8%99%AB/">爬虫</a>
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title">友情链接</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="http://cnblogs.hankleo.com" title="博客园">博客园</a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://hank-leo.github.io/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>