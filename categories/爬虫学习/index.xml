<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>爬虫学习 on Hank&#39;s Blog</title>
    <link>https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 爬虫学习 on Hank&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 26 Aug 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>PyMongo&#43;PyQuery案例实战</title>
      <link>https://hank-leo.github.io/post/spider/PyMongo&#43;PyQuery%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98/</link>
      <pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hank-leo.github.io/post/spider/PyMongo&#43;PyQuery%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98/</guid>
      <description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 import requests import logging import re import pymongo from pyquery import PyQuery as pq from urllib.parse import urljoin import multiprocessing logging.basicConfig(level=logging.INFO,format=&amp;#39;%(asctime)s-%(levelname)s:%(message)s&amp;#39;) BASE_URL=&amp;#39;https://static1.scrape.cuiqingcai.com&amp;#39; TOTAL_PAGE=10 MONGO_CONNECTION_STRING=&amp;#39;mongodb://localhost:27017&amp;#39; MONGO_DB_NAME=&amp;#39;movies&amp;#39; MONGO_COLLECTION_NAME=&amp;#39;movies&amp;#39; client=pymongo.MongoClient(MONGO_CONNECTION_STRING) db=client[&amp;#39;movies&amp;#39;] collection=db[&amp;#39;movies&amp;#39;] def scrape_page(url): logging.info(&amp;#39;scraping %s...&amp;#39;,url) try: response=requests.get(url) if response.status_code==200: return response.text logging.error(&amp;#39;get invalid status code %swhile scraping %s&amp;#39;,response.status_code,url) except requests.RequestException: logging.error(&amp;#34;error occurred while</description>
    </item>
    
    <item>
      <title>存储数据之excel</title>
      <link>https://hank-leo.github.io/post/spider/%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B9%8Bexcel/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hank-leo.github.io/post/spider/%E5%AD%98%E5%82%A8%E6%95%B0%E6%8D%AE%E4%B9%8Bexcel/</guid>
      <description>第一种方式是使用pandas库 def save(data): data = pd.DataFrame(data) data.to_excel(index=False) 第二种方式是使用openpyxl库 import openpyxl def save(title, head, data): outwb = openpyxl.Workbook() outws = outwb.active outws.title=title for h in range(len(head)): outws.cell(1,h+1).value=head[h] for row in data: outws.append(row) outwb.save(&amp;quot;path&amp;quot;) 第三种方式是使用xlwt库 def save(title, head, data): workbook = xlwt.Workbook(encoding=&#39;utf8&#39;) sheet = workbook.add_sheet(title, cell_overwrite_ok=True) for h in range(len(head)): sheet.write(0, h, head[h]) i = 1 for list in data: j = 0 for data in list: sheet.write(i, j, data) j += 1 i += 1 workbook.save(path)</description>
    </item>
    
    <item>
      <title>解析与提取数据之re</title>
      <link>https://hank-leo.github.io/post/spider/%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE%E4%B9%8Bre/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hank-leo.github.io/post/spider/%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE%E4%B9%8Bre/</guid>
      <description>对比xpath, re对文本结构的数据处理更加灵活 #导入包 import re def get_data(response): #提取内容 title = re.findall(&amp;quot;^&amp;lt;span&amp;gt;(.*?)&amp;lt;/span&amp;gt;&amp;quot;,response, re.S)</description>
    </item>
    
    <item>
      <title>解析与提取数据之xpath</title>
      <link>https://hank-leo.github.io/post/spider/%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE%E4%B9%8Bxpath/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hank-leo.github.io/post/spider/%E8%A7%A3%E6%9E%90%E4%B8%8E%E6%8F%90%E5%8F%96%E6%95%B0%E6%8D%AE%E4%B9%8Bxpath/</guid>
      <description>日常工作主要使用xpath进行数据的解析和提取，归于xpath有着强大的功能，适应大多数的网页结构。 #导入包 from lxml import etree def get_data(response): html=etree.HTML(response) #提取属性值 url=html.xpath(&amp;quot;//div[@href]&amp;quot;) #提取文本 title=html.xpath(&amp;quot;//div[@class=&#39;title&#39;]/text()&amp;quot;)</description>
    </item>
    
  </channel>
</rss>