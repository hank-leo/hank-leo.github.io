<!doctype html>
<html lang="zh-CN">
<head>
	<meta name="generator" content="Hugo 0.62.2" />

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Hank&#39;s Blog | 专注于Python、SQL、爬虫、数据分析/挖掘/可视化</title>
    <meta property="og:title" content="Hank&#39;s Blog | 专注于Python、SQL、爬虫、数据分析/挖掘/可视化">
    <meta property="og:type" content="website">
    <meta name="Keywords" content="Hank,博客,python">
    <meta name="description" content="专注于IT互联网，包括但不限于Python、零售分析、爬虫等">
    <meta property="og:url" content="https://hank-leo.github.io/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://hank-leo.github.io/index.xml" title="Hank's Blog" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
    
    
    
        <link rel="stylesheet" href='/css/douban.css'>
    
        <link rel="stylesheet" href='/css/other.css'>
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <h1>
                        <a id="logo" href="https://hank-leo.github.io">
                            Hank&#39;s Blog
                        </a>
                    </h1>
                
                <p class="description">专注于Python、SQL、爬虫、数据分析/挖掘/可视化</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://hank-leo.github.io">首页</a>
                    
                    <a  href="https://hank-leo.github.io/archives/" title="归档">归档</a>
                    
                    <a  href="https://hank-leo.github.io/tags/" title="标签">标签</a>
                    
                    <a  href="https://hank-leo.github.io/categories/" title="分类">分类</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/" title="Scrapy框架 基本命令">Scrapy框架 基本命令</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            创建爬虫项目 scrapy startproject [项目名称] 创建爬虫文件 scrapy genspider +文件名+网址 运行(crawl) scrapy crawl 爬虫名称 # -o output 输出数据到文件 scrapy crawl [爬虫名称] -o zufang.json scrapy crawl [爬虫名称] -o zufang.csv check检查错误 scrapy check list返回项目所有spider scrapy list view 存储、打开网页 scrapy view http://www.baidu.com scrapy shell, 进入终端 scrapy shell https://www.baidu.com scrapy runspider scrapy runspider zufang_spider.py……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%99%BB%E5%BD%95%E7%BD%91%E7%AB%99/" title="Scrapy框架 登录网站">Scrapy框架 登录网站</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            使用cookies登录网站 import scrapy class LoginSpider(scrapy.Spider): name = 'login' allowed_domains = ['xxx.com'] start_urls = ['https://www.xxx.com/xx/'] cookies = &quot;&quot; def start_requests(self): for url in self.start_urls: yield scrapy.Request(url, cookies=self.cookies, callback=self.parse) def parse(self, response): with open(&quot;01login.html&quot;, &quot;wb&quot;) as f: f.write(response.body) 发送post请求登录, 要手动解析网页获取登录参数 import scrapy class LoginSpider(scrapy.Spider): name='login_code' allowed_domains = ['xxx.com'] #1. 登录页面 start_urls = ['https://www.xxx.com/login/'] def parse(self, response): #2. 代码登录 login_url='https://www.xxx.com/login' formdata={ &quot;username&quot;:&quot;xxx&quot;, &quot;pwd&quot;:&quot;xxx&quot;, &quot;formhash&quot;:response.xpath(&quot;//input[@id='formhash']/@value&quot;).extract_first(), &quot;backurl&quot;:response.xpath(&quot;//input[@id='backurl']/@value&quot;).extract_first() } #3. 发送登录请求post yield scrapy.FormRequest(login_url, formdata=formdata, callback=self.parse_login) def parse_login(self, response): #4.访问目标页面 member_url=&quot;https://www.xxx.com/member&quot; yield scrapy.Request(member_url, callback=self.parse_member) def parse_member(self, response): with open(&quot;02login.html&quot;,'wb') as……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%99%BB%E5%BD%95%E7%BD%91%E7%AB%99/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-Request%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/" title="Scrapy框架:Request回调函数">Scrapy框架:Request回调函数</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            Request回调函数 def parse_page1(self, response): return scrapy.Request(&quot;http://www.example.com/some_page.html&quot;, callback=self.parse_page2) def parse_page2(self, response): # this would log http://www.example.com/some_page.html self.logger.info(&quot;Visited %s&quot;, response.url) 传递参数 def parse_page1(self, response): item = MyItem() item['name'] = response.css('.name::text').extract_first() request = scrapy.Request(&quot;http://www.example.com/some_page.html&quot;, callback=self.parse_page2) request.meta['item'] = item yield request def parse_page2(self, response): item = response.meta['item'] item['age'] = response.css('.age::text').extract_first() yield item……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-Request%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-settings-py/" title="Scrapy框架:Settings.py">Scrapy框架:Settings.py</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            #Scrapy项目名字 BOT_NAME = 'segmentfault' #Scrapy搜索spider的模块列表 SPIDER_MODULES = ['segmentfault.spiders'] #使用爬虫创建命令genspider创建爬虫时生成的模块 NEWSPIDER_MODULE = 'segmentfault.spiders' #默认的USER_AGENT, 使用BOT_NAME配置生成，建议覆盖 #USER_AGNET = 'segmentfault (+http://www.yourdomain.com)' #如果启用，Scrapy则会遵守网站Rebots.txt协议，建议设……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-settings-py/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/" title="Scrapy框架:入门案例">Scrapy框架:入门案例</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            创建项目: scrappy start project maitian 明确要抓取的字段items.py import scrapy class MaitianItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() title = scrapy.Field() price = scrapy.Field() area = scrapy.Field() district = scrapy.Field() 在spider目录下创建爬虫文件: zufang_spider.py 2.1 创建一个类，并继承scrapy的一个子类: scrapy.Spider 2.2 自定义爬取名, name=&quot;&quot; 后面运行框架需要用到； 2.3 定义爬取目标网址 2.4 定义scrapy的方法 下面是简……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/" title="Scrapy框架:异常处理">Scrapy框架:异常处理</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            import scrapy from scrapy.spidermiddlewares.httperror import HttpError from twisted.internet.error import DNSLookupError from twisted.internet.error import TimeoutError, TCPTimedOutError class ErrbackSpider(scrapy.Spider): name = &quot;errback_example&quot; start_urls = [ &quot;http://www.httpbin.org/&quot;, # 正常HTTP 200返回 &quot;http://www.httpbin.org/status/404&quot;, # 404 Not found error &quot;http://www.httpbin.org/status/500&quot;, # 500服务器错误 &quot;http://www.httpbin.org:12345/&quot;, # 超时无响应错误 &quot;http://www.httphttpbinbin.org/&quot;, # DNS 错误 ] def start_requests(self): for u in self.start_urls: yield scrapy.Request(u, callback=self.parse_httpbin, errback=self.errback_httpbin, dont_filter=True) def parse_httpbin(self, response): self.logger.info('Got successful response from {}'.format(response.url)) # 其他处理. def errback_httpbin(self, failure): # 日志记录所有的异常信息 self.logger.error(repr(failure)) # 假设我们需要对指定的异常类型做处理， # 我们需要判断异常的类型 if……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/scrapy%E6%A1%86%E6%9E%B6-%E6%8A%93%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1TOP100/" title="Scrapy框架:抓取猫眼电影TOP100">Scrapy框架:抓取猫眼电影TOP100</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            需求： 抓取的数据为电影名称、主演、上映日期、评分。将抓取的数据保存到maoyantop100.json文件，并将文件作为附件通过邮件发送给接收人。 创建项目 scrapy startproject maoyan scrapy genspider -t crawl top100 maoyan.com 编写items.py # -*- coding: utf-8 -*- import scrapy class MaoyanItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() # 电影名称 name = scrapy.Field() # 主演 actors = scrapy.Field() # 上映时间 releasetime = scrapy.Field()……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/scrapy%E6%A1%86%E6%9E%B6-%E6%8A%93%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1TOP100/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%88%AC%E5%8F%96%E9%93%BE%E5%AE%B6%E4%BA%8C%E6%89%8B%E6%88%BF%E4%BF%A1%E6%81%AF/" title="Scrapy框架:爬取链家二手房信息">Scrapy框架:爬取链家二手房信息</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            创建爬虫项目 scrapy startproject lianjiahouse 创建爬虫文件 scrapy genspider -t craw house lianjia.com 编写items.py文件 # -*- coding: utf-8 -*- # Define here the models for your scraped items # # See documentation in: # https://doc.scrapy.org/en/latest/topics/items.html import scrapy class LianjiahouseItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() # 发布信息名称 house_name = scrapy.Field() # 小区名称 community_name = scrapy.Field() # 所在区域 # location = scrapy.Field() # 链家编号 house_record = scrapy.Field() # 总售价 total_amount = scrapy.Field() # 单价 unit_price = scrapy.Field() # 房屋基本信息 # 建筑面积 area_total = scrapy.Field() # 套内面积 area_use……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%88%AC%E5%8F%96%E9%93%BE%E5%AE%B6%E4%BA%8C%E6%89%8B%E6%88%BF%E4%BF%A1%E6%81%AF/">阅读全文</a></p>
    </article>
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86/" title="Scrapy框架:统计数据收集">Scrapy框架:统计数据收集</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            通过stats属性来使用数据收集器 class ExtensionThatAccessStats(object): def __init__(self, stats): self.stats = stats @classmethod def from_crawler(cls, crawler): return cls(crawler.stats) 设置数据 stats.set_value('hostname', socket.gethostname()) 增加数据值 stats.inc_value('pages_crawled') 当新的值比原来的值大时设置数据 stats.max_value('max_items_scraoed', value) 当新的值比原来的值小时设置数据 stats.min_value('min_free_memory_percent', value) 获取数据 stats.get_value('pages_crawled') 获取所有数据 stats.get_stats() 示例：统计名人名言网站(http://quotes.toscrape.com/)标签为love的名言数……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86/">阅读全文</a></p>
    </article>
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://hank-leo.github.io/page/4/">上一页</a>
    </li>
    

    
    <li >
        <a href="https://hank-leo.github.io/">1</a>
    </li>
    
    <li >
        <a href="https://hank-leo.github.io/page/2/">2</a>
    </li>
    
    <li >
        <a href="https://hank-leo.github.io/page/3/">3</a>
    </li>
    
    <li >
        <a href="https://hank-leo.github.io/page/4/">4</a>
    </li>
    
    <li  class="current">
        <a href="https://hank-leo.github.io/page/5/">5</a>
    </li>
    

    
</ol>



</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://hank-leo.github.io">Hank&#39;s Blog By Hank</a>
        
    </div>
    <br />
    
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




    <script src='/js/douban.js'></script>

                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://hank-leo.github.io/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://hank-leo.github.io">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://hank-leo.github.io/post/sql/LeetCode-SQL%E5%88%B7%E9%A2%98%E8%AE%B0%E5%BD%95/" title="LeetCode SQL刷题记录">LeetCode SQL刷题记录</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/spider/%E7%88%AC%E5%8F%96%E6%9F%90%E8%91%97%E5%90%8D%E5%BF%AB%E9%A4%90%E5%B7%A8%E5%A4%B4%E9%97%A8%E5%BA%97%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%88%98/" title="爬取某著名快餐巨头门店数据实战">爬取某著名快餐巨头门店数据实战</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/spider/Aiohttp&#43;PyMongo%E5%BC%82%E6%AD%A5%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98/" title="Aiohttp&#43;PyMongo异步案例实战">Aiohttp&#43;PyMongo异步案例实战</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/spider/PyMongo&#43;PyQuery%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98/" title="PyMongo&#43;PyQuery案例实战">PyMongo&#43;PyQuery案例实战</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/sql/SQL%E5%A4%8D%E4%B9%A0/" title="SQL复习">SQL复习</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/app/%E4%BD%BF%E7%94%A8Airtest%E7%88%AC%E5%8F%96%E6%9F%90%E5%92%96%E5%95%A1app%E6%95%B0%E6%8D%AEv1/" title="使用Airtest爬取某咖啡app数据">使用Airtest爬取某咖啡app数据</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/app/%E4%BD%BF%E7%94%A8Airtest%E7%88%AC%E5%8F%96%E6%9F%90%E5%92%96%E5%95%A1app%E6%95%B0%E6%8D%AEv2/" title="使用Airtest爬取某咖啡app数据v1">使用Airtest爬取某咖啡app数据v1</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/blog/%E4%BD%BF%E7%94%A8Github-Actions%E6%90%AD%E5%BB%BAhugo/" title="使用Github Actions搭建hugo">使用Github Actions搭建hugo</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/python/%E4%BD%BF%E7%94%A8%E5%BC%82%E6%AD%A5%E5%87%BD%E6%95%B0%E8%8E%B7%E5%8F%96%E6%96%87%E4%BB%B6%E5%90%8D/" title="使用异步函数获取文件名">使用异步函数获取文件名</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/spider/pyqt/%E5%88%A9%E7%94%A8PyQt5%E4%BA%A4%E4%BA%92%E5%AF%BC%E5%87%BA%E6%95%B0%E6%8D%AE/" title="利用PyQt5交互导出数据">利用PyQt5交互导出数据</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
    <li><a href="https://hank-leo.github.io/categories/Python%E5%AD%A6%E4%B9%A0/">Python学习 (6)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/Python%E5%AE%9E%E6%88%98/">Python实战 (2)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/">Scrapy框架学习 (11)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/">博客搭建 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0/">数据分析学习 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/">数据分析实战 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%A5%E5%91%8A/">数据分析报告 (1)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/">数据可视化 (1)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/">数据库学习 (5)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E6%80%9D%E7%BB%B4/">数据思维 (1)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/">爬虫学习 (4)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98/">爬虫实战 (4)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E5%AE%9E%E6%88%98/">爬虫实战实战 (1)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">统计学 (2)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/">面试题 (2)</a></li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://hank-leo.github.io/tags/MongoDB/">MongoDB</a>
    
    <a href="https://hank-leo.github.io/tags/MySQL/">MySQL</a>
    
    <a href="https://hank-leo.github.io/tags/Python%E9%9D%A2%E8%AF%95/">Python面试</a>
    
    <a href="https://hank-leo.github.io/tags/Scrapy/">Scrapy</a>
    
    <a href="https://hank-leo.github.io/tags/aiohttp/">aiohttp</a>
    
    <a href="https://hank-leo.github.io/tags/airtest/">airtest</a>
    
    <a href="https://hank-leo.github.io/tags/app/">app</a>
    
    <a href="https://hank-leo.github.io/tags/dict/">dict</a>
    
    <a href="https://hank-leo.github.io/tags/excel/">excel</a>
    
    <a href="https://hank-leo.github.io/tags/hexo/">hexo</a>
    
    <a href="https://hank-leo.github.io/tags/hugo/">hugo</a>
    
    <a href="https://hank-leo.github.io/tags/list/">list</a>
    
    <a href="https://hank-leo.github.io/tags/numpy/">numpy</a>
    
    <a href="https://hank-leo.github.io/tags/pandas/">pandas</a>
    
    <a href="https://hank-leo.github.io/tags/pyecharts/">pyecharts</a>
    
    <a href="https://hank-leo.github.io/tags/pymongo/">pymongo</a>
    
    <a href="https://hank-leo.github.io/tags/pyqt5/">pyqt5</a>
    
    <a href="https://hank-leo.github.io/tags/re/">re</a>
    
    <a href="https://hank-leo.github.io/tags/regex/">regex</a>
    
    <a href="https://hank-leo.github.io/tags/requests/">requests</a>
    
    <a href="https://hank-leo.github.io/tags/string/">string</a>
    
    <a href="https://hank-leo.github.io/tags/superset/">superset</a>
    
    <a href="https://hank-leo.github.io/tags/xlwings/">xlwings</a>
    
    <a href="https://hank-leo.github.io/tags/xpath/">xpath</a>
    
    <a href="https://hank-leo.github.io/tags/%E5%BC%82%E6%AD%A5/">异步</a>
    
    <a href="https://hank-leo.github.io/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/">数据清洗</a>
    
    <a href="https://hank-leo.github.io/tags/%E7%88%AC%E8%99%AB%E9%9D%A2%E8%AF%95/">爬虫面试</a>
    
</div>
    </section>

    
<section class="widget">
    <h3 class="widget-title">友情链接</h3>
    <ul class="widget-list">
        
        <li>
            <a target="_blank" href="http://cnblogs.hankleo.com" title="博客园">博客园</a>
        </li>
        
    </ul>
</section>


    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://hank-leo.github.io/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>