<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>爬虫实战 on Hank&#39;s Blog</title>
    <link>https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98/</link>
    <description>Recent content in 爬虫实战 on Hank&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Wed, 26 Aug 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Aiohttp&#43;PyMongo异步案例实战</title>
      <link>https://hank-leo.github.io/post/spider/Aiohttp&#43;PyMongo%E5%BC%82%E6%AD%A5%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98/</link>
      <pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hank-leo.github.io/post/spider/Aiohttp&#43;PyMongo%E5%BC%82%E6%AD%A5%E6%A1%88%E4%BE%8B%E5%AE%9E%E6%88%98/</guid>
      <description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 import json import asyncio import aiohttp import logging from motor.motor_asyncio import AsyncIOMotorClient logging.basicConfig(level=logging.INFO,format=&amp;#34;%(asctime)s- %(levelname)s: %(message)s&amp;#34;) MONGO_CONNECTION_STRING = &amp;#34;mongodb://localhost:27017&amp;#34; MONGO_DB_NAME = &amp;#34;books&amp;#34; MONGO_COLLECTION_NAME = &amp;#34;books&amp;#34; client = AsyncIOMotorClient(MONGO_CONNECTION_STRING) db = client[MONGO_DB_NAME] collection = db[MONGO_COLLECTION_NAME] INDEX_URL = &amp;#34;https://dynamic5.scrape.cuiqingcai.com/api/book/?limit=18&amp;amp;offset={offset}&amp;#34; DETAIL_URL = &amp;#34;https://dynamic5.scrape.cuiqingcai.com/detail/{id}&amp;#34; PAGE_SIZE = 18 PAGE_NUMBER = 100 CONCURRENCY = 5 semaphore = asyncio.Semaphore(CONCURRENCY) session = None async def scrape_api(url): async with semaphore: try: logging.info(&amp;#34;scraping %s&amp;#34;, url) async with session.get(url) as response: return await</description>
    </item>
    
    <item>
      <title>使用Airtest爬取某咖啡app数据</title>
      <link>https://hank-leo.github.io/post/app/%E4%BD%BF%E7%94%A8Airtest%E7%88%AC%E5%8F%96%E6%9F%90%E5%92%96%E5%95%A1app%E6%95%B0%E6%8D%AEv1/</link>
      <pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hank-leo.github.io/post/app/%E4%BD%BF%E7%94%A8Airtest%E7%88%AC%E5%8F%96%E6%9F%90%E5%92%96%E5%95%A1app%E6%95%B0%E6%8D%AEv1/</guid>
      <description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 # -*- encoding=utf8 -*- __author__ = &amp;#34;Hank&amp;#34; from airtest.core.api import * from poco.drivers.android.uiautomation import AndroidUiautomationPoco poco = AndroidUiautomationPoco(use_airtest_input=True, screenshot_each_action=False) auto_setup(__file__) import time import random import pandas as pd page_data=[] while True: city=poco(name=&amp;#39;com.lucky.luckyclient:id/tv_select_city&amp;#39;).get_text() result_obj = poco(&amp;#34;com.lucky.luckyclient:id/frameLayout&amp;#34;).offspring(&amp;#34;com.lucky.luckyclient:id/lv_address_list&amp;#34;).child(&amp;#34;android.widget.LinearLayout&amp;#34;) for result in result_obj: brand = result.child(&amp;#34;android.widget.LinearLayout&amp;#34;).child(&amp;#34;android.widget.LinearLayout&amp;#34;).child(name=&amp;#39;com.lucky.luckyclient:id/iv_shop_brand&amp;#39;).get_text() name = result.child(&amp;#34;android.widget.LinearLayout&amp;#34;).child(&amp;#34;android.widget.LinearLayout&amp;#34;).child(name=&amp;#39;com.lucky.luckyclient:id/tv_dept_name&amp;#39;).get_text() address = result.child(&amp;#34;android.widget.LinearLayout&amp;#34;).child(&amp;#34;android.widget.LinearLayout&amp;#34;).child(name=&amp;#39;com.lucky.luckyclient:id/tv_dept_address&amp;#39;).get_text() city=poco(name=&amp;#39;com.lucky.luckyclient:id/tv_select_city&amp;#39;).get_text() data = city, name, address, brand s=str(city)+str(name)+str(address)+str(brand) if &amp;#34;UIObjectProxy&amp;#34; in s: pass else: page_data.append(data) print(data) end = poco(text=&amp;#34;已经全部加载完成&amp;#34;)</description>
    </item>
    
    <item>
      <title>使用Airtest爬取某咖啡app数据v1</title>
      <link>https://hank-leo.github.io/post/app/%E4%BD%BF%E7%94%A8Airtest%E7%88%AC%E5%8F%96%E6%9F%90%E5%92%96%E5%95%A1app%E6%95%B0%E6%8D%AEv2/</link>
      <pubDate>Wed, 26 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hank-leo.github.io/post/app/%E4%BD%BF%E7%94%A8Airtest%E7%88%AC%E5%8F%96%E6%9F%90%E5%92%96%E5%95%A1app%E6%95%B0%E6%8D%AEv2/</guid>
      <description>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 # -*- encoding=utf8 -*- __author__ = &amp;#34;Hank&amp;#34; import os import time import json import shutil import random import requests import traceback</description>
    </item>
    
    <item>
      <title>使用Airtest进行App爬虫</title>
      <link>https://hank-leo.github.io/post/app/%E4%BD%BF%E7%94%A8Airtest%E8%BF%9B%E8%A1%8CApp%E7%88%AC%E8%99%AB/</link>
      <pubDate>Fri, 06 Dec 2019 00:00:00 +0000</pubDate>
      
      <guid>https://hank-leo.github.io/post/app/%E4%BD%BF%E7%94%A8Airtest%E8%BF%9B%E8%A1%8CApp%E7%88%AC%E8%99%AB/</guid>
      <description>前言 Airtest是网易开发的手机UI戒面自动化测试工具， 安装 从Airtest官网 : https://airtest.netease.com 下载Airtest，然后像安装普通软件一样安装即可。 手机连接 启动Airtest以后，把Android手机连接到电脑上，点击下图方框中的refresh ADB 然后点击connect按钮 开始爬虫 以某品牌咖</description>
    </item>
    
  </channel>
</rss>