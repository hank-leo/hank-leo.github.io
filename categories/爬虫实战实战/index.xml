<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>爬虫实战实战 on Hank&#39;s Blog</title>
    <link>https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E5%AE%9E%E6%88%98/</link>
    <description>Recent content in 爬虫实战实战 on Hank&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <lastBuildDate>Thu, 27 Aug 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E5%AE%9E%E6%88%98/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>爬取某著名快餐巨头门店数据实战</title>
      <link>https://hank-leo.github.io/post/spider/%E7%88%AC%E5%8F%96%E6%9F%90%E8%91%97%E5%90%8D%E5%BF%AB%E9%A4%90%E5%B7%A8%E5%A4%B4%E9%97%A8%E5%BA%97%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%88%98/</link>
      <pubDate>Thu, 27 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://hank-leo.github.io/post/spider/%E7%88%AC%E5%8F%96%E6%9F%90%E8%91%97%E5%90%8D%E5%BF%AB%E9%A4%90%E5%B7%A8%E5%A4%B4%E9%97%A8%E5%BA%97%E6%95%B0%E6%8D%AE%E5%AE%9E%E6%88%98/</guid>
      <description>项目说明 通过python代码抓取*德基官网门店数据 爬取过程 首先查看网页结构可知，数据以json格式存储 要拿到请求参数才能访问数据，这里的参数主要是cname，也就是城市信息 解析网页信息，获取城市数据 1 2 3 4 5 6 7 8 9 10 11 def get_city(self): try: resp=session.get(url=self.base_url,headers=self.headers,verify=False).content.decode() sel=Selector(resp) all_li=sel.xpath(&amp;#34;//ul[@class=&amp;#39;shen_info&amp;#39;]/li&amp;#34;) for p in all_li: all_a=p.xpath(&amp;#34;./div[@class=&amp;#39;shen_city&amp;#39;]/a&amp;#34;) for c in all_a: city=c.xpath(&amp;#34;./text()&amp;#34;).get() except Exception: traceback.print_exc() 这里用到Selecto</description>
    </item>
    
  </channel>
</rss>