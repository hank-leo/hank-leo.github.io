<!doctype html>
<html lang="zh-CN">
<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Posts | Hank&#39;s Blog</title>
    <meta property="og:title" content="Posts - Hank&#39;s Blog">
    <meta property="og:type" content="article">
        
        
    <meta name="Keywords" content="python,sql,go,">
    <meta name="description" content="Posts">
        
    <meta name="author" content="Hank">
    <meta property="og:url" content="https://hank-leo.github.io/post/">
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

    <link rel="stylesheet" href='/css/normalize.css'>
    <link rel="stylesheet" href='/css/style.css'>
    <link rel="alternate" type="application/rss+xml+xml" href="https://hank-leo.github.io/post/index.xml" title="Hank's Blog" />
    <script type="text/javascript" src="//cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js"></script>

    
    
    
        <link href="https://cdn.bootcdn.net/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" rel="stylesheet">
    
    
    
    
        <link rel="stylesheet" href='/css/douban.css'>
    
        <link rel="stylesheet" href='/css/other.css'>
    
</head>


<body>
    <header id="header" class="clearfix">
    <div class="container">
        <div class="col-group">
            <div class="site-name ">
                
                    <a id="logo" href="https://hank-leo.github.io">
                        Hank&#39;s Blog
                    </a>
                
                <p class="description">专注于爬虫、数据分析与挖掘,涉及python、sql、go、js</p>
            </div>
            <div>
                <nav id="nav-menu" class="clearfix">
                    <a class="current" href="https://hank-leo.github.io">首页</a>
                    
                    <a class="current" href="https://hank-leo.github.io/post/" title="归档">归档</a>
                    
                    <a  href="https://hank-leo.github.io/tags/" title="标签">标签</a>
                    
                    <a  href="https://hank-leo.github.io/categories/" title="分类">分类</a>
                    
                    <a  href="https://hank-leo.github.io/about/" title="关于">关于</a>
                    
                </nav>
            </div>
        </div>
    </div>
</header>

    <div id="body">
        <div class="container">
            <div class="col-group">

                <div class="col-8" id="main">
                    
<div class="res-cons">
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/python/xpath%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/" title="Xpath的实际应用">Xpath的实际应用</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月5日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Python%E5%AD%A6%E4%B9%A0'>Python学习</a></span>
            
        </div>
        
        <div class="post-content">
            xpath中使用contains xpath(span[contanins(@class, 'xxx')]) Xpath如何选择不包含某一个属性的节点? 这里可以用到 not 例如排除一个属性的节点可以使用 //tbody/tr[not(@class)] 排除一个或者两个属性可以使用 //tbody/tr[not(@class or @id)] xpath按序选择 有时候我们在选择的时候可能某些属性同时匹配了多个节点，但是我们只想要其中的某个节点，如第二个节点，或者最……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/python/xpath%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/sql/MongoDB%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/" title="MongoDB的实际应用">MongoDB的实际应用</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月5日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0'>数据库学习</a></span>
            
        </div>
        
        <div class="post-content">
            MongoDB基本操作 1.数据库操作 使用use DATABASE_NAME创建数据库 use maitian 如果数据库不存在，就创建数据库，否则切换到指定的数据库 使用show dbs查看所有数据库 show dbs 使用db.dropDatabase()删除数据库 use maitian db.dropDatabase() 2.集合操作 在maitian数据库中创建名为zuf……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/sql/MongoDB%E7%9A%84%E5%AE%9E%E9%99%85%E5%BA%94%E7%94%A8/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86/" title="Scrapy框架:统计数据收集">Scrapy框架:统计数据收集</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            通过stats属性来使用数据收集器 class ExtensionThatAccessStats(object): def __init__(self, stats): self.stats = stats @classmethod def from_crawler(cls, crawler): return cls(crawler.stats) 设置数据 stats.set_value('hostname', socket.gethostname()) 增加数据值 stats.inc_value('pages_crawled') 当新的值比原来的值大时设置数据 stats.max_value('max_items_scraoed', value) 当新的值比原来的值小时设置数据 stats.min_value('min_free_memory_percent', value) 获取数据 stats.get_value('pages_crawled') 获取所有数据 stats.get_stats() 示例：统计名人名言网站(http://quotes.toscrape.com/)标签为love的名言数……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%88%AC%E5%8F%96%E9%93%BE%E5%AE%B6%E4%BA%8C%E6%89%8B%E6%88%BF%E4%BF%A1%E6%81%AF/" title="Scrapy框架:爬取链家二手房信息">Scrapy框架:爬取链家二手房信息</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            创建爬虫项目 scrapy startproject lianjiahouse 创建爬虫文件 scrapy genspider -t craw house lianjia.com 编写items.py文件 # -*- coding: utf-8 -*- # Define here the models for your scraped items # # See documentation in: # https://doc.scrapy.org/en/latest/topics/items.html import scrapy class LianjiahouseItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() # 发布信息名称 house_name = scrapy.Field() # 小区名称 community_name = scrapy.Field() # 所在区域 # location = scrapy.Field() # 链家编号 house_record = scrapy.Field() # 总售价 total_amount = scrapy.Field() # 单价 unit_price = scrapy.Field() # 房屋基本信息 # 建筑面积 area_total = scrapy.Field() # 套内面积 area_use……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%88%AC%E5%8F%96%E9%93%BE%E5%AE%B6%E4%BA%8C%E6%89%8B%E6%88%BF%E4%BF%A1%E6%81%AF/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/scrapy%E6%A1%86%E6%9E%B6-%E6%8A%93%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1TOP100/" title="Scrapy框架:抓取猫眼电影TOP100">Scrapy框架:抓取猫眼电影TOP100</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            需求： 抓取的数据为电影名称、主演、上映日期、评分。将抓取的数据保存到maoyantop100.json文件，并将文件作为附件通过邮件发送给接收人。 创建项目 scrapy startproject maoyan scrapy genspider -t crawl top100 maoyan.com 编写items.py # -*- coding: utf-8 -*- import scrapy class MaoyanItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() # 电影名称 name = scrapy.Field() # 主演 actors = scrapy.Field() # 上映时间 releasetime = scrapy.Field()……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/scrapy%E6%A1%86%E6%9E%B6-%E6%8A%93%E5%8F%96%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1TOP100/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/" title="Scrapy框架:异常处理">Scrapy框架:异常处理</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            import scrapy from scrapy.spidermiddlewares.httperror import HttpError from twisted.internet.error import DNSLookupError from twisted.internet.error import TimeoutError, TCPTimedOutError class ErrbackSpider(scrapy.Spider): name = &quot;errback_example&quot; start_urls = [ &quot;http://www.httpbin.org/&quot;, # 正常HTTP 200返回 &quot;http://www.httpbin.org/status/404&quot;, # 404 Not found error &quot;http://www.httpbin.org/status/500&quot;, # 500服务器错误 &quot;http://www.httpbin.org:12345/&quot;, # 超时无响应错误 &quot;http://www.httphttpbinbin.org/&quot;, # DNS 错误 ] def start_requests(self): for u in self.start_urls: yield scrapy.Request(u, callback=self.parse_httpbin, errback=self.errback_httpbin, dont_filter=True) def parse_httpbin(self, response): self.logger.info('Got successful response from {}'.format(response.url)) # 其他处理. def errback_httpbin(self, failure): # 日志记录所有的异常信息 self.logger.error(repr(failure)) # 假设我们需要对指定的异常类型做处理， # 我们需要判断异常的类型 if……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/" title="Scrapy框架:入门案例">Scrapy框架:入门案例</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            创建项目: scrappy start project maitian 明确要抓取的字段items.py import scrapy class MaitianItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() title = scrapy.Field() price = scrapy.Field() area = scrapy.Field() district = scrapy.Field() 在spider目录下创建爬虫文件: zufang_spider.py 2.1 创建一个类，并继承scrapy的一个子类: scrapy.Spider 2.2 自定义爬取名, name=&quot;&quot; 后面运行框架需要用到； 2.3 定义爬取目标网址 2.4 定义scrapy的方法 下面是简……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E5%85%A5%E9%97%A8%E6%A1%88%E4%BE%8B/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-settings-py/" title="Scrapy框架:Settings.py">Scrapy框架:Settings.py</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            #Scrapy项目名字 BOT_NAME = 'segmentfault' #Scrapy搜索spider的模块列表 SPIDER_MODULES = ['segmentfault.spiders'] #使用爬虫创建命令genspider创建爬虫时生成的模块 NEWSPIDER_MODULE = 'segmentfault.spiders' #默认的USER_AGENT, 使用BOT_NAME配置生成，建议覆盖 #USER_AGNET = 'segmentfault (+http://www.yourdomain.com)' #如果启用，Scrapy则会遵守网站Rebots.txt协议，建议设……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-settings-py/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-Request%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/" title="Scrapy框架:Request回调函数">Scrapy框架:Request回调函数</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            Request回调函数 def parse_page1(self, response): return scrapy.Request(&quot;http://www.example.com/some_page.html&quot;, callback=self.parse_page2) def parse_page2(self, response): # this would log http://www.example.com/some_page.html self.logger.info(&quot;Visited %s&quot;, response.url) 传递参数 def parse_page1(self, response): item = MyItem() item['name'] = response.css('.name::text').extract_first() request = scrapy.Request(&quot;http://www.example.com/some_page.html&quot;, callback=self.parse_page2) request.meta['item'] = item yield request def parse_page2(self, response): item = response.meta['item'] item['age'] = response.css('.age::text').extract_first() yield item……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-Request%E5%9B%9E%E8%B0%83%E5%87%BD%E6%95%B0/">阅读全文</a></p>
    </article>
    
    
    
    <article class="post">
        <header>
            <h1 class="post-title">
                <a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%99%BB%E5%BD%95%E7%BD%91%E7%AB%99/" title="Scrapy框架 登录网站">Scrapy框架 登录网站</a>
            </h1>
        </header>
        <date class="post-meta meta-date">
            2019年12月4日
        </date>
        
        <div class="post-meta">
            <span>|</span>
            
            <span class="meta-category"><a href='https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0'>Scrapy框架学习</a></span>
            
        </div>
        
        <div class="post-content">
            使用cookies登录网站 import scrapy class LoginSpider(scrapy.Spider): name = 'login' allowed_domains = ['xxx.com'] start_urls = ['https://www.xxx.com/xx/'] cookies = &quot;&quot; def start_requests(self): for url in self.start_urls: yield scrapy.Request(url, cookies=self.cookies, callback=self.parse) def parse(self, response): with open(&quot;01login.html&quot;, &quot;wb&quot;) as f: f.write(response.body) 发送post请求登录, 要手动解析网页获取登录参数 import scrapy class LoginSpider(scrapy.Spider): name='login_code' allowed_domains = ['xxx.com'] #1. 登录页面 start_urls = ['https://www.xxx.com/login/'] def parse(self, response): #2. 代码登录 login_url='https://www.xxx.com/login' formdata={ &quot;username&quot;:&quot;xxx&quot;, &quot;pwd&quot;:&quot;xxx&quot;, &quot;formhash&quot;:response.xpath(&quot;//input[@id='formhash']/@value&quot;).extract_first(), &quot;backurl&quot;:response.xpath(&quot;//input[@id='backurl']/@value&quot;).extract_first() } #3. 发送登录请求post yield scrapy.FormRequest(login_url, formdata=formdata, callback=self.parse_login) def parse_login(self, response): #4.访问目标页面 member_url=&quot;https://www.xxx.com/member&quot; yield scrapy.Request(member_url, callback=self.parse_member) def parse_member(self, response): with open(&quot;02login.html&quot;,'wb') as……
        </div>
        <p class="readmore"><a href="https://hank-leo.github.io/post/scrapy/Scrapy%E6%A1%86%E6%9E%B6-%E7%99%BB%E5%BD%95%E7%BD%91%E7%AB%99/">阅读全文</a></p>
    </article>
    
    
    



<ol class="page-navigator">
    
    <li class="prev">
        <a href="https://hank-leo.github.io/post/page/5/">上一页</a>
    </li>
    

    
    <li >
        <a href="https://hank-leo.github.io/post/">1</a>
    </li>
    
    <li >
        <a href="https://hank-leo.github.io/post/page/2/">2</a>
    </li>
    
    <li >
        <a href="https://hank-leo.github.io/post/page/3/">3</a>
    </li>
    
    <li >
        <a href="https://hank-leo.github.io/post/page/4/">4</a>
    </li>
    
    <li >
        <a href="https://hank-leo.github.io/post/page/5/">5</a>
    </li>
    
    <li  class="current">
        <a href="https://hank-leo.github.io/post/page/6/">6</a>
    </li>
    
    <li >
        <a href="https://hank-leo.github.io/post/page/7/">7</a>
    </li>
    

    
    <li class="next">
        <a href="https://hank-leo.github.io/post/page/7/">下一页</a>
    </li>
    
</ol>



</div>

                    <footer id="footer">
    <div>
        &copy; 2020 <a href="https://hank-leo.github.io">Hank&#39;s Blog By Hank</a>
        
    </div>
    <br />
    
</footer>



<a id="rocket" href="#top"></a>
<script type="text/javascript" src='/js/totop.js?v=0.0.0' async=""></script>



    <script type="text/javascript" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script>




    <script src='/js/douban.js'></script>

                </div>

                <div id="secondary">
    <section class="widget">
        <form id="search" action='https://hank-leo.github.io/search/' method="get" accept-charset="utf-8" target="_blank" _lpchecked="1">
      
      <input type="text" name="q" maxlength="20" placeholder="Search">
      <input type="hidden" name="sitesearch" value="https://hank-leo.github.io">
      <button type="submit" class="submit icon-search"></button>
</form>
    </section>
    
    <section class="widget">
        <h3 class="widget-title">最近文章</h3>
<ul class="widget-list">
    
    <li>
        <a href="https://hank-leo.github.io/post/analysis/Pandas%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/" title="Pandas基础操作">Pandas基础操作</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/analysis/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E7%B1%BB%E7%BD%91%E7%AB%99%E5%90%88%E9%9B%86/" title="数据分析类网站合集">数据分析类网站合集</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/go/Docker%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BD%BF%E7%94%A8/" title="Docker学习与使用">Docker学习与使用</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/excel/Excel%E5%90%88%E5%B9%B6/" title="Excel合并">Excel合并</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/python/GUI-Tkinter%E7%99%BB%E9%99%86/" title="GUI Tkinter登陆">GUI Tkinter登陆</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/analysis/PyEcharts%E5%8F%AF%E8%A7%86%E5%8C%96%E5%85%A5%E9%97%A8/" title="PyEcharts可视化入门">PyEcharts可视化入门</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/excel/Python%E5%BF%AB%E9%80%9F%E8%AE%BE%E7%BD%AEExcel%E8%A1%A8%E6%A0%BC%E8%BE%B9%E6%A1%86/" title="Python快速设置Excel表格边框">Python快速设置Excel表格边框</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/algorithm/Python%E7%AE%97%E6%B3%95%E4%BE%8B11%E6%95%B4%E6%95%B0%E6%8E%92%E5%BA%8F/" title="Python算法|例11整数排序">Python算法|例11整数排序</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/algorithm/Python%E7%AE%97%E6%B3%95%E4%BE%8B16%E6%95%B0%E5%AD%97%E5%88%A4%E6%96%AD/" title="Python算法|例16数字判断">Python算法|例16数字判断</a>
    </li>
    
    <li>
        <a href="https://hank-leo.github.io/post/algorithm/Python%E7%AE%97%E6%B3%95%E4%BE%8B2%E5%88%A4%E6%96%AD%E5%B9%B3%E6%96%B9%E6%95%B0/" title="Python算法|例2判断平方数">Python算法|例2判断平方数</a>
    </li>
    
</ul>
    </section>

    

    <section class="widget">
        <h3 class="widget-title"><a href="/categories">分类</a></h3>
<ul class="widget-list">
    
    <li><a href="https://hank-leo.github.io/categories/Go%E5%AD%A6%E4%B9%A0/">Go学习 (1)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/Python%E5%AD%A6%E4%B9%A0/">Python学习 (7)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/Python%E5%AE%9E%E6%88%98/">Python实战 (2)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/Scrapy%E6%A1%86%E6%9E%B6%E5%AD%A6%E4%B9%A0/">Scrapy框架学习 (11)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/">博客搭建 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AD%A6%E4%B9%A0/">数据分析学习 (5)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98/">数据分析实战 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E6%8A%A5%E5%91%8A/">数据分析报告 (1)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/">数据可视化 (3)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%A6%E4%B9%A0/">数据库学习 (6)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E6%95%B0%E6%8D%AE%E6%80%9D%E7%BB%B4/">数据思维 (1)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0/">爬虫学习 (4)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98/">爬虫实战 (4)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%88%AC%E8%99%AB%E5%AE%9E%E6%88%98%E5%AE%9E%E6%88%98/">爬虫实战实战 (1)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%AE%97%E6%B3%95%E5%AD%A6%E4%B9%A0/">算法学习 (5)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E7%BB%9F%E8%AE%A1%E5%AD%A6/">统计学 (2)</a></li>
    
    <li><a href="https://hank-leo.github.io/categories/%E9%9D%A2%E8%AF%95%E9%A2%98/">面试题 (2)</a></li>
    
</ul>
    </section>

    <section class="widget">
        <h3 class="widget-title"><a href="/tags">标签</a></h3>
<div class="tagcloud">
    
    <a href="https://hank-leo.github.io/tags/MongoDB/">MongoDB</a>
    
    <a href="https://hank-leo.github.io/tags/MySQL/">MySQL</a>
    
    <a href="https://hank-leo.github.io/tags/Python%E9%9D%A2%E8%AF%95/">Python面试</a>
    
    <a href="https://hank-leo.github.io/tags/Scrapy/">Scrapy</a>
    
    <a href="https://hank-leo.github.io/tags/aiohttp/">aiohttp</a>
    
    <a href="https://hank-leo.github.io/tags/airtest/">airtest</a>
    
    <a href="https://hank-leo.github.io/tags/app/">app</a>
    
    <a href="https://hank-leo.github.io/tags/dict/">dict</a>
    
    <a href="https://hank-leo.github.io/tags/docker/">docker</a>
    
    <a href="https://hank-leo.github.io/tags/excel/">excel</a>
    
    <a href="https://hank-leo.github.io/tags/hexo/">hexo</a>
    
    <a href="https://hank-leo.github.io/tags/hugo/">hugo</a>
    
    <a href="https://hank-leo.github.io/tags/list/">list</a>
    
    <a href="https://hank-leo.github.io/tags/numpy/">numpy</a>
    
    <a href="https://hank-leo.github.io/tags/pandas/">pandas</a>
    
    <a href="https://hank-leo.github.io/tags/pyecharts/">pyecharts</a>
    
    <a href="https://hank-leo.github.io/tags/pymongo/">pymongo</a>
    
    <a href="https://hank-leo.github.io/tags/pyqt5/">pyqt5</a>
    
    <a href="https://hank-leo.github.io/tags/re/">re</a>
    
    <a href="https://hank-leo.github.io/tags/regex/">regex</a>
    
    <a href="https://hank-leo.github.io/tags/requests/">requests</a>
    
    <a href="https://hank-leo.github.io/tags/string/">string</a>
    
    <a href="https://hank-leo.github.io/tags/superset/">superset</a>
    
    <a href="https://hank-leo.github.io/tags/tableau/">tableau</a>
    
    <a href="https://hank-leo.github.io/tags/tkinter/">tkinter</a>
    
    <a href="https://hank-leo.github.io/tags/xlwings/">xlwings</a>
    
    <a href="https://hank-leo.github.io/tags/xpath/">xpath</a>
    
    <a href="https://hank-leo.github.io/tags/%E5%BC%82%E6%AD%A5/">异步</a>
    
    <a href="https://hank-leo.github.io/tags/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/">数据清洗</a>
    
    <a href="https://hank-leo.github.io/tags/%E7%88%AC%E8%99%AB%E9%9D%A2%E8%AF%95/">爬虫面试</a>
    
    <a href="https://hank-leo.github.io/tags/%E8%B5%84%E6%BA%90/">资源</a>
    
</div>
    </section>

    

    <section class="widget">
        <h3 class="widget-title">其它</h3>
        <ul class="widget-list">
            <li><a href="https://hank-leo.github.io/index.xml">文章 RSS</a></li>
        </ul>
    </section>
</div>
            </div>
        </div>
    </div>
</body>

</html>